{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import Generic_Para_Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  15  16  17  18  19  20  21  \\\n",
       "0   1   6   4  12   5   5   3   4   1  67  ...   0   0   1   0   0   1   0   \n",
       "1   2  48   2  60   1   3   2   2   1  22  ...   0   0   1   0   0   1   0   \n",
       "2   4  12   4  21   1   4   3   3   1  49  ...   0   0   1   0   0   1   0   \n",
       "3   1  42   2  79   1   4   3   4   2  45  ...   0   0   0   0   0   0   0   \n",
       "4   1  24   3  49   1   3   3   4   4  53  ...   1   0   1   0   0   0   0   \n",
       "5   4  36   2  91   5   3   3   4   4  35  ...   0   0   1   0   0   0   0   \n",
       "6   4  24   2  28   3   5   3   4   2  53  ...   0   0   1   0   0   1   0   \n",
       "7   2  36   2  69   1   3   3   2   3  35  ...   0   1   1   0   1   0   0   \n",
       "8   4  12   2  31   4   4   1   4   1  61  ...   0   0   1   0   0   1   0   \n",
       "9   2  30   4  52   1   1   4   2   3  28  ...   1   0   1   0   0   1   0   \n",
       "\n",
       "   22  23  24  \n",
       "0   0   1   1  \n",
       "1   0   1   2  \n",
       "2   1   0   1  \n",
       "3   0   1   1  \n",
       "4   0   1   2  \n",
       "5   1   0   1  \n",
       "6   0   1   1  \n",
       "7   0   0   1  \n",
       "8   1   0   1  \n",
       "9   0   0   2  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../Datasets/german.data-numeric'\n",
    "HCV = pd.read_csv(file, delimiter=',', sep='delimiter', header=None)\n",
    "print(HCV.shape)\n",
    "HCV.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.577000</td>\n",
       "      <td>20.903000</td>\n",
       "      <td>2.54500</td>\n",
       "      <td>32.711000</td>\n",
       "      <td>2.105000</td>\n",
       "      <td>3.384000</td>\n",
       "      <td>2.68200</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>2.358000</td>\n",
       "      <td>35.546000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.713000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.257638</td>\n",
       "      <td>12.058814</td>\n",
       "      <td>1.08312</td>\n",
       "      <td>28.252605</td>\n",
       "      <td>1.580023</td>\n",
       "      <td>1.208306</td>\n",
       "      <td>0.70808</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>1.050209</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423584</td>\n",
       "      <td>0.304111</td>\n",
       "      <td>0.290578</td>\n",
       "      <td>0.198389</td>\n",
       "      <td>0.383544</td>\n",
       "      <td>0.452588</td>\n",
       "      <td>0.146757</td>\n",
       "      <td>0.4002</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>0.458487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1           2            3            4   \\\n",
       "count  1000.000000  1000.000000  1000.00000  1000.000000  1000.000000   \n",
       "mean      2.577000    20.903000     2.54500    32.711000     2.105000   \n",
       "std       1.257638    12.058814     1.08312    28.252605     1.580023   \n",
       "min       1.000000     4.000000     0.00000     2.000000     1.000000   \n",
       "25%       1.000000    12.000000     2.00000    14.000000     1.000000   \n",
       "50%       2.000000    18.000000     2.00000    23.000000     1.000000   \n",
       "75%       4.000000    24.000000     4.00000    40.000000     3.000000   \n",
       "max       4.000000    72.000000     4.00000   184.000000     5.000000   \n",
       "\n",
       "                5           6            7            8            9   ...  \\\n",
       "count  1000.000000  1000.00000  1000.000000  1000.000000  1000.000000  ...   \n",
       "mean      3.384000     2.68200     2.845000     2.358000    35.546000  ...   \n",
       "std       1.208306     0.70808     1.103718     1.050209    11.375469  ...   \n",
       "min       1.000000     1.00000     1.000000     1.000000    19.000000  ...   \n",
       "25%       3.000000     2.00000     2.000000     1.000000    27.000000  ...   \n",
       "50%       3.000000     3.00000     3.000000     2.000000    33.000000  ...   \n",
       "75%       5.000000     3.00000     4.000000     3.000000    42.000000  ...   \n",
       "max       5.000000     4.00000     4.000000     4.000000    75.000000  ...   \n",
       "\n",
       "                15           16           17           18           19  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.234000     0.103000     0.907000     0.041000     0.179000   \n",
       "std       0.423584     0.304111     0.290578     0.198389     0.383544   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                20           21         22           23           24  \n",
       "count  1000.000000  1000.000000  1000.0000  1000.000000  1000.000000  \n",
       "mean      0.713000     0.022000     0.2000     0.630000     1.300000  \n",
       "std       0.452588     0.146757     0.4002     0.483046     0.458487  \n",
       "min       0.000000     0.000000     0.0000     0.000000     1.000000  \n",
       "25%       0.000000     0.000000     0.0000     0.000000     1.000000  \n",
       "50%       1.000000     0.000000     0.0000     1.000000     1.000000  \n",
       "75%       1.000000     0.000000     0.0000     1.000000     2.000000  \n",
       "max       1.000000     1.000000     1.0000     1.000000     2.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HCV.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Target Variable:\n",
      " 1    700\n",
      "2    300\n",
      "Name: 24, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "HCV.columns = HCV.columns.astype(str)\n",
    "\n",
    "HCV['24'] = HCV['24'].astype(str)\n",
    "\n",
    "print(\"Distribution of Target Variable:\\n\", HCV['24'].value_counts())\n",
    "\n",
    "categories = HCV['24']\n",
    "\n",
    "num_cat = len(categories.value_counts())\n",
    "\n",
    "values = np.array(categories)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "labels = pd.DataFrame(onehot_encoded)\n",
    "\n",
    "#print(label_encoder.classes_)\n",
    "\n",
    "data = HCV.drop('24', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Value Counts:\n",
      "1.0    490\n",
      "0.0    210\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "Upsampled Training Data Value Counts:\n",
      "1.0    490\n",
      "0.0    300\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.fillna(0, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=4, stratify=labels)\n",
    "y_train_min = y_train[y_train[1]==1]\n",
    "X_train_min = X_train[y_train[1]==1]\n",
    "\n",
    "y_train_maj = y_train[y_train[1]==0]\n",
    "X_train_maj = X_train[y_train[1]==0]\n",
    "\n",
    "X_upsampled , y_upsampled = resample(X_train_min, y_train_min,\n",
    "                        n_samples=300,\n",
    "                        random_state=123)\n",
    "\n",
    "\n",
    "X_train_up = pd.concat([X_train_maj, X_upsampled])\n",
    "y_train_up = pd.concat([y_train_maj, y_upsampled])\n",
    "\n",
    "print(\"Training Data Value Counts:\")\n",
    "print(y_train[0].value_counts())\n",
    "\n",
    "print(\"\\nUpsampled Training Data Value Counts:\")\n",
    "print(y_train_up[0].value_counts())\n",
    "\n",
    "#X_train, y_train = X_train_up, y_train_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>7.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.103829e-17</td>\n",
       "      <td>-8.857994e-17</td>\n",
       "      <td>1.732741e-16</td>\n",
       "      <td>-1.601893e-17</td>\n",
       "      <td>1.284687e-16</td>\n",
       "      <td>3.743038e-17</td>\n",
       "      <td>-9.103829e-17</td>\n",
       "      <td>-2.302920e-16</td>\n",
       "      <td>-1.733534e-16</td>\n",
       "      <td>-2.950021e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.294996e-16</td>\n",
       "      <td>1.693883e-16</td>\n",
       "      <td>-1.222831e-16</td>\n",
       "      <td>2.077703e-16</td>\n",
       "      <td>-1.393330e-16</td>\n",
       "      <td>-1.416327e-16</td>\n",
       "      <td>-1.728776e-17</td>\n",
       "      <td>5.126058e-16</td>\n",
       "      <td>-2.807278e-16</td>\n",
       "      <td>2.283887e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "      <td>1.000715e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.228496e+00</td>\n",
       "      <td>-1.380883e+00</td>\n",
       "      <td>-2.284716e+00</td>\n",
       "      <td>-1.055204e+00</td>\n",
       "      <td>-6.965943e-01</td>\n",
       "      <td>-1.963113e+00</td>\n",
       "      <td>-2.391748e+00</td>\n",
       "      <td>-1.687559e+00</td>\n",
       "      <td>-1.320262e+00</td>\n",
       "      <td>-1.473431e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041241e-01</td>\n",
       "      <td>-5.663521e-01</td>\n",
       "      <td>-3.412146e-01</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "      <td>-2.294157e-01</td>\n",
       "      <td>-4.594265e-01</td>\n",
       "      <td>-1.592279e+00</td>\n",
       "      <td>-1.624591e-01</td>\n",
       "      <td>-4.932943e-01</td>\n",
       "      <td>-1.292964e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.228496e+00</td>\n",
       "      <td>-7.345317e-01</td>\n",
       "      <td>-4.786165e-01</td>\n",
       "      <td>-6.787473e-01</td>\n",
       "      <td>-6.965943e-01</td>\n",
       "      <td>-3.094679e-01</td>\n",
       "      <td>-9.692980e-01</td>\n",
       "      <td>-7.746599e-01</td>\n",
       "      <td>-1.320262e+00</td>\n",
       "      <td>-7.671123e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041241e-01</td>\n",
       "      <td>-5.663521e-01</td>\n",
       "      <td>-3.412146e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>-2.294157e-01</td>\n",
       "      <td>-4.594265e-01</td>\n",
       "      <td>-1.592279e+00</td>\n",
       "      <td>-1.624591e-01</td>\n",
       "      <td>-4.932943e-01</td>\n",
       "      <td>-1.292964e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.300306e-01</td>\n",
       "      <td>-2.497685e-01</td>\n",
       "      <td>-4.786165e-01</td>\n",
       "      <td>-3.365136e-01</td>\n",
       "      <td>-6.965943e-01</td>\n",
       "      <td>-3.094679e-01</td>\n",
       "      <td>4.531519e-01</td>\n",
       "      <td>1.382390e-01</td>\n",
       "      <td>5.813501e-01</td>\n",
       "      <td>-2.373735e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041241e-01</td>\n",
       "      <td>-5.663521e-01</td>\n",
       "      <td>-3.412146e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>-2.294157e-01</td>\n",
       "      <td>-4.594265e-01</td>\n",
       "      <td>6.280305e-01</td>\n",
       "      <td>-1.624591e-01</td>\n",
       "      <td>-4.932943e-01</td>\n",
       "      <td>7.734168e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.166900e+00</td>\n",
       "      <td>2.349947e-01</td>\n",
       "      <td>1.327483e+00</td>\n",
       "      <td>2.795072e-01</td>\n",
       "      <td>5.666596e-01</td>\n",
       "      <td>5.173548e-01</td>\n",
       "      <td>4.531519e-01</td>\n",
       "      <td>1.051138e+00</td>\n",
       "      <td>5.813501e-01</td>\n",
       "      <td>5.572348e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041241e-01</td>\n",
       "      <td>-5.663521e-01</td>\n",
       "      <td>-3.412146e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>-2.294157e-01</td>\n",
       "      <td>-4.594265e-01</td>\n",
       "      <td>6.280305e-01</td>\n",
       "      <td>-1.624591e-01</td>\n",
       "      <td>-4.932943e-01</td>\n",
       "      <td>7.734168e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.166900e+00</td>\n",
       "      <td>4.113101e+00</td>\n",
       "      <td>1.327483e+00</td>\n",
       "      <td>5.139227e+00</td>\n",
       "      <td>1.829914e+00</td>\n",
       "      <td>1.344177e+00</td>\n",
       "      <td>1.875602e+00</td>\n",
       "      <td>1.051138e+00</td>\n",
       "      <td>1.532156e+00</td>\n",
       "      <td>3.470799e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.898979e+00</td>\n",
       "      <td>1.765686e+00</td>\n",
       "      <td>2.930707e+00</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>4.358899e+00</td>\n",
       "      <td>2.176627e+00</td>\n",
       "      <td>6.280305e-01</td>\n",
       "      <td>6.155395e+00</td>\n",
       "      <td>2.027187e+00</td>\n",
       "      <td>7.734168e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02   \n",
       "mean  -9.103829e-17 -8.857994e-17  1.732741e-16 -1.601893e-17  1.284687e-16   \n",
       "std    1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00   \n",
       "min   -1.228496e+00 -1.380883e+00 -2.284716e+00 -1.055204e+00 -6.965943e-01   \n",
       "25%   -1.228496e+00 -7.345317e-01 -4.786165e-01 -6.787473e-01 -6.965943e-01   \n",
       "50%   -4.300306e-01 -2.497685e-01 -4.786165e-01 -3.365136e-01 -6.965943e-01   \n",
       "75%    1.166900e+00  2.349947e-01  1.327483e+00  2.795072e-01  5.666596e-01   \n",
       "max    1.166900e+00  4.113101e+00  1.327483e+00  5.139227e+00  1.829914e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02   \n",
       "mean   3.743038e-17 -9.103829e-17 -2.302920e-16 -1.733534e-16 -2.950021e-17   \n",
       "std    1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00   \n",
       "min   -1.963113e+00 -2.391748e+00 -1.687559e+00 -1.320262e+00 -1.473431e+00   \n",
       "25%   -3.094679e-01 -9.692980e-01 -7.746599e-01 -1.320262e+00 -7.671123e-01   \n",
       "50%   -3.094679e-01  4.531519e-01  1.382390e-01  5.813501e-01 -2.373735e-01   \n",
       "75%    5.173548e-01  4.531519e-01  1.051138e+00  5.813501e-01  5.572348e-01   \n",
       "max    1.344177e+00  1.875602e+00  1.051138e+00  1.532156e+00  3.470799e+00   \n",
       "\n",
       "       ...            14            15            16            17  \\\n",
       "count  ...  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02   \n",
       "mean   ... -1.294996e-16  1.693883e-16 -1.222831e-16  2.077703e-16   \n",
       "std    ...  1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00   \n",
       "min    ... -2.041241e-01 -5.663521e-01 -3.412146e-01 -3.000000e+00   \n",
       "25%    ... -2.041241e-01 -5.663521e-01 -3.412146e-01  3.333333e-01   \n",
       "50%    ... -2.041241e-01 -5.663521e-01 -3.412146e-01  3.333333e-01   \n",
       "75%    ... -2.041241e-01 -5.663521e-01 -3.412146e-01  3.333333e-01   \n",
       "max    ...  4.898979e+00  1.765686e+00  2.930707e+00  3.333333e-01   \n",
       "\n",
       "                 18            19            20            21            22  \\\n",
       "count  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02  7.000000e+02   \n",
       "mean  -1.393330e-16 -1.416327e-16 -1.728776e-17  5.126058e-16 -2.807278e-16   \n",
       "std    1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00  1.000715e+00   \n",
       "min   -2.294157e-01 -4.594265e-01 -1.592279e+00 -1.624591e-01 -4.932943e-01   \n",
       "25%   -2.294157e-01 -4.594265e-01 -1.592279e+00 -1.624591e-01 -4.932943e-01   \n",
       "50%   -2.294157e-01 -4.594265e-01  6.280305e-01 -1.624591e-01 -4.932943e-01   \n",
       "75%   -2.294157e-01 -4.594265e-01  6.280305e-01 -1.624591e-01 -4.932943e-01   \n",
       "max    4.358899e+00  2.176627e+00  6.280305e-01  6.155395e+00  2.027187e+00   \n",
       "\n",
       "                 23  \n",
       "count  7.000000e+02  \n",
       "mean   2.283887e-16  \n",
       "std    1.000715e+00  \n",
       "min   -1.292964e+00  \n",
       "25%   -1.292964e+00  \n",
       "50%    7.734168e-01  \n",
       "75%    7.734168e-01  \n",
       "max    7.734168e-01  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval('X_'+dataset_name).iloc[batch_mask].values\n",
    "    #print(batch_x)\n",
    "    if dataset_name == 'train':\n",
    "        batch_y = eval('y_'+dataset_name).iloc[batch_mask].values\n",
    "        \n",
    "    return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in each layer\n",
    "input_num_units = X_train.shape[1]\n",
    "hidden_num_units1 = 16\n",
    "hidden_num_units2 = 8\n",
    "output_num_units = num_cat\n",
    "\n",
    "# define placeholders\n",
    "x = tf.placeholder(tf.float32, [None, input_num_units])\n",
    "y = tf.placeholder(tf.float32, [None, output_num_units])\n",
    "\n",
    "# set remaining variables\n",
    "epochs = 2000\n",
    "batch_size = X_train.shape[0]\n",
    "batch_size = 512\n",
    "learning_rate = 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define weights and biases of the neural network\n",
    "\n",
    "weights = {\n",
    "    'hidden1': tf.Variable(tf.random_normal([input_num_units, hidden_num_units1], seed=seed)),\n",
    "    'hidden2': tf.Variable(tf.random_normal([hidden_num_units1, hidden_num_units2], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_num_units2, output_num_units], seed=seed))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden1': tf.Variable(tf.random_normal([hidden_num_units1], seed=seed)),\n",
    "    'hidden2': tf.Variable(tf.random_normal([hidden_num_units2], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adityapandey/Desktop/Sem 8/Project/Code/A-ReLU-Parabolic/Generic Para/Generic_Para_Func.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/adityapandey/Desktop/Sem 8/Project/Code/A-ReLU-Parabolic/Generic Para/Generic_Para_Func.py:43: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "hidden_layer1 = tf.add(tf.matmul(x, weights['hidden1']), biases['hidden1'])\n",
    "hidden_layer1 = Generic_Para_Func.tf_generic_para_func(hidden_layer1)\n",
    "#hidden_layer1 = tf.nn.relu(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = tf.add(tf.matmul(hidden_layer1, weights['hidden2']), biases['hidden2'])\n",
    "#hidden_layer2 = Generic_Para_Func.tf_generic_para_func(hidden_layer2)\n",
    "#hidden_layer2 = tf.nn.sigmoid(hidden_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adityapandey/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "output_layer = tf.add(tf.matmul(hidden_layer2, weights['output']), biases['output'])\n",
    "\n",
    "logits = output_layer\n",
    "prediction = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "#loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training....\n",
      "Step 1, Minibatch Loss= 194.6482, Training Accuracy= 0.371\n",
      "Step 50, Minibatch Loss= 57.7410, Training Accuracy= 0.602\n",
      "Step 100, Minibatch Loss= 22.2503, Training Accuracy= 0.643\n",
      "Step 150, Minibatch Loss= 11.2243, Training Accuracy= 0.697\n",
      "Step 200, Minibatch Loss= 7.1654, Training Accuracy= 0.738\n",
      "Step 250, Minibatch Loss= 4.4048, Training Accuracy= 0.744\n",
      "Step 300, Minibatch Loss= 3.2766, Training Accuracy= 0.760\n",
      "Step 350, Minibatch Loss= 2.1156, Training Accuracy= 0.787\n",
      "Step 400, Minibatch Loss= 1.8799, Training Accuracy= 0.795\n",
      "Step 450, Minibatch Loss= 1.3340, Training Accuracy= 0.809\n",
      "Step 500, Minibatch Loss= 0.9587, Training Accuracy= 0.807\n",
      "Step 550, Minibatch Loss= 0.9327, Training Accuracy= 0.770\n",
      "Step 600, Minibatch Loss= 0.7029, Training Accuracy= 0.846\n",
      "Step 650, Minibatch Loss= 0.8092, Training Accuracy= 0.787\n",
      "Step 700, Minibatch Loss= 0.6457, Training Accuracy= 0.795\n",
      "Step 750, Minibatch Loss= 0.5701, Training Accuracy= 0.816\n",
      "Step 800, Minibatch Loss= 0.4082, Training Accuracy= 0.848\n",
      "Step 850, Minibatch Loss= 0.5555, Training Accuracy= 0.820\n",
      "Step 900, Minibatch Loss= 0.4957, Training Accuracy= 0.809\n",
      "Step 950, Minibatch Loss= 0.3764, Training Accuracy= 0.838\n",
      "Step 1000, Minibatch Loss= 0.4631, Training Accuracy= 0.816\n",
      "Step 1050, Minibatch Loss= 0.4147, Training Accuracy= 0.857\n",
      "Step 1100, Minibatch Loss= 0.4113, Training Accuracy= 0.850\n",
      "Step 1150, Minibatch Loss= 0.3990, Training Accuracy= 0.857\n",
      "Step 1200, Minibatch Loss= 0.3560, Training Accuracy= 0.889\n",
      "Step 1250, Minibatch Loss= 0.3724, Training Accuracy= 0.846\n",
      "Step 1300, Minibatch Loss= 0.3995, Training Accuracy= 0.844\n",
      "Step 1350, Minibatch Loss= 0.3651, Training Accuracy= 0.857\n",
      "Step 1400, Minibatch Loss= 0.3701, Training Accuracy= 0.836\n",
      "Step 1450, Minibatch Loss= 0.3218, Training Accuracy= 0.863\n",
      "Step 1500, Minibatch Loss= 0.2852, Training Accuracy= 0.887\n",
      "Step 1550, Minibatch Loss= 0.3476, Training Accuracy= 0.869\n",
      "Step 1600, Minibatch Loss= 0.3434, Training Accuracy= 0.848\n",
      "Step 1650, Minibatch Loss= 0.3321, Training Accuracy= 0.869\n",
      "Step 1700, Minibatch Loss= 0.3745, Training Accuracy= 0.846\n",
      "Step 1750, Minibatch Loss= 0.3476, Training Accuracy= 0.828\n",
      "Step 1800, Minibatch Loss= 0.3083, Training Accuracy= 0.867\n",
      "Step 1850, Minibatch Loss= 0.3478, Training Accuracy= 0.875\n",
      "Step 1900, Minibatch Loss= 0.3750, Training Accuracy= 0.846\n",
      "Step 1950, Minibatch Loss= 0.3347, Training Accuracy= 0.877\n",
      "Step 2000, Minibatch Loss= 0.3414, Training Accuracy= 0.844\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "display_step=50\n",
    "\n",
    "pred = []\n",
    "actual = []\n",
    "\n",
    "loss_vals=[[],[]]\n",
    "\n",
    "print(\"\\nTraining....\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, epochs+1):\n",
    "        batch_x, batch_y = batch_creator(batch_size, X_train.shape[0], 'train')\n",
    "\n",
    "        sess.run(train_op, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={x: batch_x,\n",
    "                                                                 y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \"{:.3f}\".format(acc))\n",
    "            loss_vals[0].append(step)\n",
    "            loss_vals[1].append(loss)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    #print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: X_train, y: y_train}))\n",
    "    \n",
    "    \n",
    "    pred.append(tf.argmax(output_layer, 1).eval({x: X_test, y: y_test}))\n",
    "    actual.append(tf.argmax(y, 1).eval({y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 173  37\n",
      "  47  43\n",
      "Testing Accuracy 72.0\n",
      "\n",
      "Precision of 1: 78.64\n",
      "Recall of 1: 82.38\n",
      "F-Score of 1: 80.47\n",
      "Accuracy w.r.t. 1: 72.0\n",
      "\n",
      "Precision of 2: 53.75\n",
      "Recall of 2: 47.78\n",
      "F-Score of 2: 50.59\n",
      "Accuracy w.r.t. 2: 72.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(list(actual[0]), list(pred[0]), labels=[0, 1])\n",
    "print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in cm]))\n",
    "#confusionmatrix = np.matrix(cm)\n",
    "def perf_measure(ans, conf_list):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    s=0\n",
    "    total=0\n",
    "    for i in range(len(conf_list)):\n",
    "        for j in range(len(conf_list)):\n",
    "            total+=ans[i][j]\n",
    "    for i in range(len(conf_list)):\n",
    "        TP.append(ans[i][i])\n",
    "        s=0\n",
    "        for j in range(len(conf_list)):\n",
    "            if(j!=i):\n",
    "                s+=ans[j][i]\n",
    "        FP.append(s)\n",
    "        FN.append(sum(ans[i])-TP[i])\n",
    "        TN.append(total-TP[i]-FP[i]-FN[i])\n",
    "    return(TP, FP, TN, FN)\n",
    "    \n",
    "conf_list = list(label_encoder.classes_)\n",
    "tp,fp,tn,fn=perf_measure(cm, conf_list)\n",
    "final_accuracy =0.0\n",
    "final_precision = 0.0\n",
    "final_recall = 0.0\n",
    "acc = np.diag(cm)/np.sum(cm)\n",
    "acc *= 100\n",
    "acc = sum(acc)\n",
    "\n",
    "print(\"Testing Accuracy\", round(acc,2))\n",
    "print()\n",
    "\n",
    "for i in range(len(conf_list)):\n",
    "    accuracy=(tp[i]+tn[i])/(tp[i]+tn[i]+fp[i]+fn[i]) * 100\n",
    "    precision = tp[i] / (tp[i]+fp[i]) * 100\n",
    "    recall = tp[i] / (tp[i]+fn[i]) * 100\n",
    "    Fscore = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"Precision of \",conf_list[i],\": \",round(precision,2),sep=\"\")\n",
    "    print(\"Recall of \",conf_list[i],\": \",round(recall,2),sep=\"\")\n",
    "    print(\"F-Score of \",conf_list[i],\": \",round(Fscore,2),sep=\"\")\n",
    "    print(\"Accuracy w.r.t. \",conf_list[i],\": \",round(accuracy,2),sep=\"\")\n",
    "    print()\n",
    "    final_precision+=precision\n",
    "    final_recall+=recall\n",
    "    final_accuracy+=accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    '''\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     verticalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plot_confusion_matrix(cm, conf_list)\n",
    "plot_confusion_matrix(cm2, conf_list, normalize=True, cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda10eb8a4a7a8449a2a0e31935e7ff31fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
