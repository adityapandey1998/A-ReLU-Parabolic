{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Beans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6b8H3iQ0Ctl"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "#tfds.disable_progress_bar()\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import datetime\n",
        "%matplotlib inline\n",
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO0WFByO0Ctp"
      },
      "source": [
        "# Enable eager execution\n",
        "# tf.enable_v2_behavior()\n",
        "\n",
        "# Check out all available datasets \n",
        "#tfds.list_builders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRhWjifU0Cts"
      },
      "source": [
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    name = 'beans', \n",
        "    split = ['train', 'validation', 'test'],\n",
        "    as_supervised = True,\n",
        "    with_info = True)\n",
        "#print(ds_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyz8lmNT0Ctv"
      },
      "source": [
        "# Image parameters:\n",
        "image_height = 500\n",
        "image_width = 500\n",
        "num_channels = 3 \n",
        "num_classes = 3 # healthy, angular leaf spot disease, bean rust disease\n",
        "\n",
        "# Pipeline hyperparameters:\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Let's keep the dimensions the same (no resizing for now)\n",
        "\n",
        "def normalize_image(image, label, target_height = 500, target_width = 500):\n",
        "    image = tf.cast(image, tf.float32)/255.\n",
        "    image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
        "    return image, label\n",
        "\n",
        "ds_train = ds_train.map(normalize_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(batch_size)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKbF0Tw50Cty"
      },
      "source": [
        "ds_validation = ds_validation.map(\n",
        "    normalize_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "ds_validation = ds_validation.batch(batch_size)\n",
        "ds_validation = ds_validation.cache()\n",
        "ds_validation = ds_validation.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFFWScT90Ct1"
      },
      "source": [
        "def return_class_labels(ds):\n",
        "    \"\"\"\"Returns a list of class labels from a `DatasetV1Adapter` object.\"\"\"\n",
        "    l_labels = []\n",
        "    for _, labels in ds.take(-1):\n",
        "        labels = labels.numpy()\n",
        "        l_labels.append(labels[:])\n",
        "    return [item for sublist in l_labels for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOhH1_470Ct4"
      },
      "source": [
        "training_labels = return_class_labels(ds_train)\n",
        "print(\"The distribution of training labels is: \", (Counter(training_labels)))\n",
        "\n",
        "validation_labels = return_class_labels(ds_validation)\n",
        "print(\"The distribution of validation labels is: \", (Counter(validation_labels)))\n",
        "      \n",
        "test_labels = return_class_labels(ds_test)\n",
        "print(\"The distribution of test labels is: \", (Counter(test_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLnx_36b0Ct8"
      },
      "source": [
        "example = ds_train.take(1)\n",
        "for sample in example:\n",
        "    image, label = sample[0], sample[1]\n",
        "    image = image.numpy()\n",
        "    label = label.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAf87su9rU5t"
      },
      "source": [
        "# Custom Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "\n",
        "def Generic_Para(x):\n",
        "    return 0.65*K.pow(x,2) + 0.5*x\n",
        "\n",
        "def SBAF_Para(x):\n",
        "    return 1 - x + K.pow(x, 2)\n",
        "\n",
        "k = 1.25\n",
        "def A_ReLU_Para(x):\n",
        "    global k\n",
        "    return k * K.pow(x, 2)\n",
        "\n",
        "def Abs_Func(x):\n",
        "    return K.abs(x)\n",
        "\n",
        "# Not Working\n",
        "def A_ReLU(x):\n",
        "  # if x>=0:\n",
        "  #   return k*K.pow(x,n)\n",
        "  # else:\n",
        "  #   return 0.0\n",
        "  # return K.clip(k*K.pow(x,n), 0, 2)\n",
        "  return 0.94*K.pow(K.abs(x),1.1)\n",
        "  # return K.switch(K.greater(x, 0), 0.94*K.pow(x,1.1), K.zeros_like(x))\n",
        "  # return K.clip(K.switch(K.greater(x, 0), K.zeros_like(x), 0.84*K.pow(x,1.1)), 0, 2)\n",
        "\n",
        "# Not working\n",
        "def Leaky_A_ReLU(x):\n",
        "  a = 0.01\n",
        "  k = 1.06\n",
        "  n = 1.1\n",
        "  if x>=0:\n",
        "    return k*K.pow(x,n)\n",
        "  else:\n",
        "    return a*k*K.pow(K.abs(x),n)\n",
        "  \n",
        "get_custom_objects().update({\n",
        "    'Generic_Para': Activation(Generic_Para),\n",
        "    'SBAF_Para': Activation(SBAF_Para),\n",
        "    'A_ReLU_Para': Activation(A_ReLU_Para),\n",
        "    'Abs_Func': Activation(Abs_Func),\n",
        "    'A_ReLU': Activation(A_ReLU),\n",
        "    'Leaky_A_ReLU': Activation(Leaky_A_ReLU)\n",
        "    })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-NFRDGu0CuB"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(15, 10, input_shape = (image_height, image_width, num_channels),\n",
        "                        strides = 2, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 4))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(15, 10, strides = 2, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 4))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(128, activation = 'A_ReLU_Para', kernel_initializer = 'he_uniform'))\n",
        "model.add(Dense(128, activation = 'swish'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))\n",
        "# Conv2D(15, 10, input_shape = (image_height, image_width, num_channels), strides = 2, padding = 'same', activation = 'relu'),\n",
        "# MaxPooling2D(pool_size = 4),\n",
        "# Dropout(0.3),\n",
        "# Conv2D(15, 10, strides = 2, padding = 'same', \n",
        "#                      activation = 'relu'),\n",
        "# MaxPooling2D(pool_size = 4),\n",
        "# Dropout(0.3),\n",
        "# Flatten(),\n",
        "# Dense(128, activation = 'relu'),\n",
        "# Dense(num_classes, activation = 'softmax'),"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HN0ue6O0CuG"
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "model.summary()\n",
        "model.compile(\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate),\n",
        "    metrics = ['accuracy'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMZ9_JdN0CuJ"
      },
      "source": [
        "num_epochs = 40\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    epochs = num_epochs,\n",
        "    verbose = 1,\n",
        "    validation_data = ds_validation,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMSv5rp60CuO"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(num_epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiQDMkoF0CuR"
      },
      "source": [
        "# tf.enable_eager_execution()\n",
        "score = model.evaluate(ds_test)\n",
        "print('\\n', 'Test accuracy:', round(score[1], 5))\n",
        "print('\\n', 'Test Loss:', round(score[0], 5))\n",
        "\n",
        "print(tfds.as_numpy(ds_test))\n",
        "from sklearn import metrics\n",
        "y_test = []\n",
        "x_test = []\n",
        "for data, labels in ds_test.take(-1):\n",
        "        labels1 = labels.numpy()\n",
        "        data1 = data.numpy()\n",
        "        y_test.extend(labels1)\n",
        "        x_test.extend(data1)\n",
        "\n",
        "# # x_test, y_test = list(ds_test)\n",
        "\n",
        "testY1 = np.array(y_test)\n",
        "testY = testY1.flatten()\n",
        "testX1 = np.array(x_test)\n",
        "\n",
        "predY = model.predict_classes(testX1)\n",
        "print(metrics.classification_report(testY, predY, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}